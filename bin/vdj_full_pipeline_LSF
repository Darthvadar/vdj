#! /usr/bin/env python

import os
import optparse

import lsf
import seqtools
import vdj
import vdj.pipeline

join = os.path.join

option_parser = optparse.OptionParser()
# option_parser.add_option('-x','--xxx',dest='xxxx',type='int')
(options,args) = option_parser.parse_args()

if len(args) != 1:
    raise ValueError, "Require a single input jobfile"

jobfile = args[0]

# PARAMETER DEFINITION

# process jobfile for input parameters
# defines the following variables:
    # basename        # unique base identifier for data
    # vdj_package_dir # directory to find scripts.  will be added to shell PATH
    # input_fasta     # the initial fasta data
    # barcode_fasta   # barcode identifiers
    # isotype_fasta   # isotype identifiers
    # analysis_dir    # full path; base directory for everything
    # min_size        # min size selection
    # max_size        # max size selection
    # packet_size     # packet size for alignment jobs
    # loci            # the loci to use for VDJ aln

execfile(jobfile)

# add script directory to path
os.environ['PATH'] = join(vdj_package_dir,'bin') + ':' + os.environ['PATH']

# working directories
parts_dir = 'parts'
log_dir = 'logs'
partition_dir = 'partitions'

# output files
raw_vdjxml = basename+'.raw.vdjxml'
aligned_file = basename+'.aligned.vdjxml'
vj_filtered_file = basename+'.VJ_filtered.vdjxml'
size_selected_file = basename + '.size%i-%i' % (min_size,max_size) + '.vdjxml'
clustered_file = basename+'.clustered.vdjxml'

locus_options = ' '.join([' --locus %s' % locus for locus in loci.split()])


# PIPELINE STARTS HERE

# 0. CONVERSION TO VDJXML
inhandle = open(input_fasta,'r')
outhandle = open(join(analysis_dir,raw_vdjxml),'w')
vdj.pipeline.fasta2vdjxml(inhandle,outhandle)
inhandle.close()
outhandle.close()

# 1. SIZE SELECTION
inhandle = open(join(analysis_dir,raw_vdjxml),'r')
outhandle = open(join(analysis_dir,size_selected_file),'w')
vdj.pipeline.size_select(inhandle,outhandle,min_size,max_size)
inhandle.close()
outhandle.close()
    
# 2. SPLIT INTO PARTS
inhandle = open(join(analysis_dir,size_selected_file),'r')
parts = vdj.pipeline.iterator2parts( vdj.parse_VDJXML(inhandle),
                                     join(analysis_dir,parts_dir,size_selected_file),
                                     packetsize,
                                     prefix='<root>',
                                     suffix='</root>')

# BARCODE ID, CODING STRAND, ISOTYPE ID, VDJ CLASSIFICATION via LSF
cmd = 'barcode_id --barcodes %s ' % barcode_fasta       # 3. BARCODE IDENTIFICATION
cmd += ' | coding_strand' + locus_options               # 4. CODING STRAND
if 'IGH' in loci:                                       # 5. ISOTYPE ID (heavy chain only)
    cmd += ' | isotype_id --IGHC %s' % isotype_fasta
cmd += ' | align_vdj' + locus_options                   # 6. VDJ CLASSIFICATION

# submit cmd to LSF for each part
jobIDs = []
logfiles = []
outnames = []
for part in parts:
    partID = part.split('.')[-1]
    partoutname = join(analysis_dir,parts_dir,basename)+'.aligned.vdjxml.'+partID
    outnames.append(partoutname)
    cmd = 'cat %s | ' + cmd + ' > %s'
    cmd = cmd % (part,partoutname)
    logfile = join(analysis_dir,log_dir,'alignment.log.')+partID
    jobID = lsf.submit_to_LSF('shared_2h',logfile,cmd)
    logfiles.append(logfile)
    jobIDs.append(jobID)
lsf.wait_for_LSF_jobs(jobIDs,logfiles)

# 7. CONCAT PARTS
outhandle = open(join(analysis_dir,aligned_file),'w')
vdj.pipeline.cat_vdjxml(outnames,outhandle)
outhandle.close()

# 8. FILTER VJ
inhandle = open(join(analysis_dir,aligned_file),'r')
outhandle = open(join(analysis_dir,vj_filtered_file),'w')
vdj.pipeline.filter_VJ(inhandle,outhandle)
inhandle.close()
outhandle.close()

# 9. PARTITION VJ
inhandle = open(join(analysis_dir,vj_filtered_file),'r')
partition_files = vdj.pipeline.partition_VJ(inhandle,join(analysis_dir,partition_dir,basename))
inhandle.close()

# 10. CLUSTER CDR3s
cmd = 'cluster_cdr3 --cutoff %f --linkage %s' % (clustering_cutoff,clustering_linkage)

# submit LSF
jobIDs = []
logfiles = []
outnames = []
for partition in partition_files:
    partitionoutname = partition.split('.')[:-1]+'.clustered.vdjxml'
    outnames.append(partitionoutname)
    tag = os.path.splitext(os.path.basename(partition))[0].split('.')[-2]
    cmd = 'cat %s | ' + cmd + ' --tag %s' + ' > %s'
    cmd = cmd % (partition,tag,partitionoutname)
    logfile = join(analysis_dir,log_dir,'clustering.')+tag+'.log'
    jobID = lsf.submit_to_LSF('shared_7d',logfile,cmd)
    logfiles.append(logfile)
    jobIDs.append(jobID)
lsf.wait_for_LSF_jobs(jobIDs,logfiles)

# 11. CONCAT PARTITIONS
outhandle = open(join(analysis_dir,clustered_file),'w')
vdj.pipeline.cat_vdjxml(outnames,outhandle)
outhandle.close()
